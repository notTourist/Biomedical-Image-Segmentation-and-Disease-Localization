{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Welcome !!\n#### As you must have guessed from the name of the notebook, this is an implementation from scratch of the UNET model , that was earlier developed for biomedical image segmentation and localization of the diseases. However, now with some modifications it is used in various other tasks like object detection, semantic segementation and also noise removal from images(by training the model for it).\n\n#### But in this notebook i have tried to build the UNET model by keeping it's architecture as close as possible to the original paper architecture.Please show some support by upvoting the notebook if you like it.\n\n#### You can read the paper from the following link https://arxiv.org/pdf/1505.04597\n","metadata":{}},{"cell_type":"code","source":"# importing the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom tensorflow.keras.utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv2D,Activation,MaxPooling2D,BatchNormalization,Conv2DTranspose,CenterCrop,Concatenate,Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nimport tensorflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-29T04:25:41.433489Z","iopub.execute_input":"2023-04-29T04:25:41.434200Z","iopub.status.idle":"2023-04-29T04:25:51.140666Z","shell.execute_reply.started":"2023-04-29T04:25:41.434159Z","shell.execute_reply":"2023-04-29T04:25:51.139580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing the dataset\nimage_path=[]\nmask_path=[]\ndf=pd.DataFrame()\nroot_path='/kaggle/input/lgg-mri-segmentation/kaggle_3m'\nfor folder in os.listdir(root_path):\n    if folder.startswith('T'):\n        for path in os.listdir(root_path+'/'+folder):\n            if 'mask' in path:\n                mask_path.append(root_path+'/'+folder+'/'+path)\n            else:\n                image_path.append(root_path+'/'+folder+'/'+path)\n                \n    elif folder=='data.csv':\n        df=pd.read_csv(root_path+'/'+folder)\n    else: \n        continue","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:25:51.142858Z","iopub.execute_input":"2023-04-29T04:25:51.143615Z","iopub.status.idle":"2023-04-29T04:25:52.357891Z","shell.execute_reply.started":"2023-04-29T04:25:51.143583Z","shell.execute_reply":"2023-04-29T04:25:52.356717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:25:52.359721Z","iopub.execute_input":"2023-04-29T04:25:52.360437Z","iopub.status.idle":"2023-04-29T04:25:52.399369Z","shell.execute_reply.started":"2023-04-29T04:25:52.360399Z","shell.execute_reply":"2023-04-29T04:25:52.398349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_id=[]\n# mask_id=[]\n# for id_ in df['Patient']:\n#     for path in image_path:\n#         if id_ in path:\n#             image_id.append(id_)\n#     for path in mask_path:\n#         if id_ in path:\n#             mask_id.append(id_)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:25:52.402310Z","iopub.execute_input":"2023-04-29T04:25:52.403062Z","iopub.status.idle":"2023-04-29T04:25:52.409545Z","shell.execute_reply.started":"2023-04-29T04:25:52.403025Z","shell.execute_reply":"2023-04-29T04:25:52.408348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_id=[id_[67:-4] for id_ in image_path]","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:25:52.411085Z","iopub.execute_input":"2023-04-29T04:25:52.411842Z","iopub.status.idle":"2023-04-29T04:25:52.423041Z","shell.execute_reply.started":"2023-04-29T04:25:52.411806Z","shell.execute_reply":"2023-04-29T04:25:52.421899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter(mask_path):\n    if np.max(cv2.imread(mask_path))>0.5:\n        return 1\n    else:\n        return 0\ndf_brain=pd.DataFrame({'Patient_id':patient_id,'Image_path':image_path,'Mask_path':mask_path})\ndf_brain['Diagnosis']=df_brain['Mask_path'].apply(lambda x: filter(x))","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:25:52.426403Z","iopub.execute_input":"2023-04-29T04:25:52.427413Z","iopub.status.idle":"2023-04-29T04:26:13.530268Z","shell.execute_reply.started":"2023-04-29T04:25:52.427378Z","shell.execute_reply":"2023-04-29T04:26:13.529249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_brain.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.531728Z","iopub.execute_input":"2023-04-29T04:26:13.532089Z","iopub.status.idle":"2023-04-29T04:26:13.546563Z","shell.execute_reply.started":"2023-04-29T04:26:13.532049Z","shell.execute_reply":"2023-04-29T04:26:13.545661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_brain.drop('Patient_id',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.547884Z","iopub.execute_input":"2023-04-29T04:26:13.548351Z","iopub.status.idle":"2023-04-29T04:26:13.562327Z","shell.execute_reply.started":"2023-04-29T04:26:13.548314Z","shell.execute_reply":"2023-04-29T04:26:13.561386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_brain_train,df_brain_test=train_test_split(df_brain,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.564004Z","iopub.execute_input":"2023-04-29T04:26:13.564328Z","iopub.status.idle":"2023-04-29T04:26:13.574706Z","shell.execute_reply.started":"2023-04-29T04:26:13.564296Z","shell.execute_reply":"2023-04-29T04:26:13.573718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_data(img_path,mask_path):\n#     x_train=[]\n#     y_train=[]\n#     for i in range(len(img_path)):\n#         img=cv2.imread(img_path[i])\n#         img=cv2.resize(img,(256,256))\n#         mask=cv2.imread(mask_path[i],cv2.IMREAD_GRAYSCALE)\n#         mask=cv2.resize(mask,(255,255))\n#         mask=np.expand_dims(mask,axis=-1)\n#         mask=mask/256\n#         x_train.append(img)\n#         y_train.append(mask)\n#     return x_train,y_train","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.581760Z","iopub.execute_input":"2023-04-29T04:26:13.582028Z","iopub.status.idle":"2023-04-29T04:26:13.590078Z","shell.execute_reply.started":"2023-04-29T04:26:13.582003Z","shell.execute_reply":"2023-04-29T04:26:13.588896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmenting data\ndef get_augmented_data(df,aug_dict,batch_size=32,image_size=(256,256)):\n    img_gen=ImageDataGenerator(**aug_dict)\n    mask_gen=ImageDataGenerator(**aug_dict)\n    image_gen=img_gen.flow_from_dataframe(df,x_col='Image_path',target_size=image_size,batch_size=batch_size,color_mode='rgb',class_mode=None)\n    mask_gen=mask_gen.flow_from_dataframe(df,x_col='Mask_path',target_size=image_size,batch_size=batch_size,color_mode='grayscale',class_mode=None)\n    for img,mask in zip(image_gen,mask_gen):\n        img=img/255\n        mask=mask/255\n        mask[mask>0.5]=1\n        mask[mask<=0.5]=0\n        yield(img,mask)\naug_dict=dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen=get_augmented_data(df_brain_train,aug_dict)\ntest_gen=get_augmented_data(df_brain_test,aug_dict={})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have to create out own loss function to calculate the loss between the original and the predicted mask, so bce_dice loss is the loss function that is used for that reason.","metadata":{}},{"cell_type":"code","source":"# Loss function\ndef bce_loss(y_true,y_pred):\n    y_true=K.cast(y_true,'float32')\n    y_pred=K.cast(y_pred,'float32')\n    return tensorflow.keras.losses.binary_crossentropy(y_true,y_pred)\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    \n    y_true_f = K.cast(y_true_f, 'float32')\n    y_pred_f = K.cast(y_pred_f, 'float32')\n    \n    intersection = K.sum(y_true_f * y_pred_f)\n    dice_coef_v = (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n    return dice_coef_v\ndef dice_loss(y_true, y_pred):\n    dice_loss_v = 1 - dice_coef(y_true, y_pred)\n    return dice_loss_v\ndef bce_dice_loss(y_true, y_pred):\n    bce_dice_loss_v = bce_loss(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return bce_dice_loss_v","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.603655Z","iopub.execute_input":"2023-04-29T04:26:13.604367Z","iopub.status.idle":"2023-04-29T04:26:13.613779Z","shell.execute_reply.started":"2023-04-29T04:26:13.604330Z","shell.execute_reply":"2023-04-29T04:26:13.612708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we will create a convolution block that will perform two convolution operations without any maxpooling in between with relu as the activation function. At last we perform the max pooling2D except if it is the last block after which we have to perform the up-convolution.","metadata":{}},{"cell_type":"code","source":"def convolution(x,num_filters,last_block=False):\n    x=Conv2D(num_filters,(3,3),padding='same')(x)\n    x=Activation('relu')(x)\n    x=Conv2D(num_filters,(3,3),padding='same')(x)\n#     bn=BatchNormalization(conv)\n    x=Activation('relu')(x)\n    skip=x\n    if not last_block:\n        x=MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n    return x,skip\n#     return x","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.615198Z","iopub.execute_input":"2023-04-29T04:26:13.615752Z","iopub.status.idle":"2023-04-29T04:26:13.627190Z","shell.execute_reply.started":"2023-04-29T04:26:13.615716Z","shell.execute_reply":"2023-04-29T04:26:13.626261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Next we create build the contracting path of the model, as shown in the paper.","metadata":{}},{"cell_type":"code","source":"starting_filters=64\ndef calculate_filters(idx):\n    return (starting_filters*(2**idx))\n\ndef contracting_path(x,num_unet_blocks=5):\n#     x=0\n    skip_connections=[]\n    for i in range(num_unet_blocks):\n        filters=calculate_filters(i)\n#         filters=64\n        last_block=i==num_unet_blocks-1\n        if last_block:\n            x,skip_input=convolution(x,filters,last_block=last_block)\n        else:    \n            x,skip_input=convolution(x,filters,last_block=last_block)\n            skip_connections.append(skip_input)\n    return x,skip_connections","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.629756Z","iopub.execute_input":"2023-04-29T04:26:13.630137Z","iopub.status.idle":"2023-04-29T04:26:13.637796Z","shell.execute_reply.started":"2023-04-29T04:26:13.630060Z","shell.execute_reply":"2023-04-29T04:26:13.636746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Next we create the expanding path by performing Conv2dTranspose.","metadata":{}},{"cell_type":"code","source":"def upconv(x,num_filters,skip_input,last_block=False):\n    x=Conv2DTranspose(num_filters,(2,2),strides=(2,2))(x)\n    if not last_block:\n        skip_crop_input=CenterCrop(height=x.shape[1],width=x.shape[2])(skip_input)\n        x=Concatenate(axis=-1)([skip_crop_input,x])\n    x=Conv2D(num_filters,(3,3),padding='same')(x)\n    x=Activation('relu')(x)\n    x=Conv2D(num_filters,(3,3),padding='same')(x)\n    x=Activation('relu')(x)\n    return x\ndef expanding_path(x,skip_connections,num_unet_blocks=4):\n    for i in range(num_unet_blocks):\n        filters=calculate_filters(num_unet_blocks-i-1)\n        x=upconv(x,filters,skip_connections[num_unet_blocks-i-1])\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.639416Z","iopub.execute_input":"2023-04-29T04:26:13.639902Z","iopub.status.idle":"2023-04-29T04:26:13.648946Z","shell.execute_reply.started":"2023-04-29T04:26:13.639749Z","shell.execute_reply":"2023-04-29T04:26:13.648019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creaing the unet model\ndef create_unet():\n    input_data=Input(shape=(256,256,3))\n    latents,skip_connections=contracting_path(input_data)\n    expanded_data=expanding_path(latents,skip_connections)\n    final_output=Conv2D(1,(1,1),activation='sigmoid')(expanded_data)\n    model=Model(inputs=[input_data],outputs=[final_output])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.664439Z","iopub.execute_input":"2023-04-29T04:26:13.664796Z","iopub.status.idle":"2023-04-29T04:26:13.672200Z","shell.execute_reply.started":"2023-04-29T04:26:13.664758Z","shell.execute_reply":"2023-04-29T04:26:13.671089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def init_model():\nmodel=create_unet()\nloss_init=bce_dice_loss\nmetrics=[dice_coef]\nepochs=32\nmodel.compile(loss=loss_init,metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:13.673586Z","iopub.execute_input":"2023-04-29T04:26:13.674040Z","iopub.status.idle":"2023-04-29T04:26:17.179524Z","shell.execute_reply.started":"2023-04-29T04:26:13.674001Z","shell.execute_reply":"2023-04-29T04:26:17.178530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:17.181889Z","iopub.execute_input":"2023-04-29T04:26:17.182620Z","iopub.status.idle":"2023-04-29T04:26:17.288664Z","shell.execute_reply.started":"2023-04-29T04:26:17.182580Z","shell.execute_reply":"2023-04-29T04:26:17.287882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,to_file='unet.png')","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:17.289743Z","iopub.execute_input":"2023-04-29T04:26:17.290190Z","iopub.status.idle":"2023-04-29T04:26:17.874763Z","shell.execute_reply.started":"2023-04-29T04:26:17.290149Z","shell.execute_reply":"2023-04-29T04:26:17.873416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying model checkpointing and early stopping\ncheckpoint=ModelCheckpoint('best_unet_model.h5',\n                           monitor='val_loss',\n                           mode='min',\n                           verbose=1,\n                           save_best_only=True)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                             patience=15,\n                             mode='min',\n                             verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:17.876688Z","iopub.execute_input":"2023-04-29T04:26:17.877421Z","iopub.status.idle":"2023-04-29T04:26:17.884281Z","shell.execute_reply.started":"2023-04-29T04:26:17.877377Z","shell.execute_reply":"2023-04-29T04:26:17.883090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\nepochs=100\nbatch_size=32\nhistory=model.fit(train_gen,\n                  epochs=epochs,\n                  steps_per_epoch=len(df_brain_train)//batch_size,\n                  validation_data=test_gen,\n                  validation_steps=len(df_brain_test)//batch_size,\n                 callbacks=[early_stopping,checkpoint])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-29T04:26:17.885931Z","iopub.execute_input":"2023-04-29T04:26:17.887169Z","iopub.status.idle":"2023-04-29T05:42:50.025945Z","shell.execute_reply.started":"2023-04-29T04:26:17.887131Z","shell.execute_reply":"2023-04-29T05:42:50.024720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model weights can be downloaded from the working directory of the kernal. Comment if you are unable to do so. Also, comment for any kind of problems related to this kernal.","metadata":{}}]}